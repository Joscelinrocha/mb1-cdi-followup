---
title: "MB1 CDI Follow-up Exclusions and Data Manipulations"
author: "The ManyBabies Analysis Team"
date: '`r format(Sys.time(), "%a %b %d %X %Y")`'
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: yes
---


# Intro

This script implements and documents exclusion criteria. We first read the full merged dataset produced by the first script `01_read_and_merge.Rmd`.

```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
knitr::opts_chunk$set(cache = TRUE)
# Define column types
col_types <- cols(
  labid = col_factor(),
  subid = col_factor(),
  CDI.form = col_factor(),
  CDI.agerange = col_factor(),
  CDI.agedays = col_integer(),
  vocab_nwords = col_integer(),
  standardized.score.CDI = col_character(),
  standardized.score.CDI.num = col_number(),
  CDI.error = col_logical(),
  Notes = col_character(),
  language = col_factor(),
  language_zone = col_factor(),
  subid_unique = col_factor(),
  trial_order = col_factor(),
  trial_num = col_factor(),
  trial_type = col_factor(),
  stimulus_num = col_factor(),
  method = col_factor(),
  age_days = col_integer(),
  age_mo = col_number(),
  age_group = col_factor(),
  nae = col_logical(),
  gender = col_factor(),
  second_session = col_logical(),
  looking_time = col_number(),
  missing = col_logical()
)
# Read data
df <- read_csv("data/01_processed_merged.csv", col_types = col_types)
```

# Exclusions

## Infants Outside Age Range

We first exclude all infants who are outside the age range described in the data collection protocol. These are:

* for the North American sample, 16 to 20 months and 22 to 26 months for the 18mo and 24mo age groups respectively;
* for all other participants sample, 17.5 to 18.5 months and 23.5 to 24.5 months.

```{r age_range}
# Age ranges
exclusions.age <- df %>%
  subset(CDI.agerange %in% c("18", "24")) %>% # Already remove "convenience" data
  mutate(CDI.agemin = map2_dbl(language_zone, as.integer(as.character(CDI.agerange)),
                               ~round((.y - if_else(.x=="NAE", 2, 1.5)) * 365/12)),
         CDI.agemax = map2_dbl(language_zone, as.integer(as.character(CDI.agerange)),
                               ~round((.y + if_else(.x=="NAE", 2, 1.5)) * 365/12))) %>%
  subset(!(CDI.agedays < CDI.agemin | CDI.agedays > CDI.agemax),
         select = -c(CDI.agemin, CDI.agemax)) %>%
  droplevels()
```

After this first exclusion, we are left with `r length(levels(exclusions.age$subid_unique))` participants out of `r length(levels(df$subid_unique))`.

## Infants Excluded from MB1 IDS

Labs sometimes recorded CDI scores regardless of the inclusion of the IDS data in the original study. Those infants and only those will have `NA` values for columns such as `trial_order`, `trial_num`, `trial_type`.

```{r IDS_exculsion}
exclusions.ids <- exclusions.age %>%
  drop_na(trial_order) %>%
  droplevels()
```

Our dataset is now reduced from `r length(levels(exclusions.age$subid_unique))` participants to `r length(levels(exclusions.ids$subid_unique))`.

## Incomplete IDS/ADS pairs

For analysis purposes, we consider pairs of ADS/IDS trials, and as such exclude any pairs in which one of the trials is missing.

```{r trial_pairs}
exclusions.pairs <- exclusions.ids %>%
  subset(!missing, select = -missing) %>%
  # We have to add vocab_nwords as some infants have multiple data points for filling the CDI twice (processed further down)
  group_by(subid_unique, CDI.agerange, vocab_nwords, stimulus_num) %>%
  mutate(pair_complete = (n() == 2)) %>%
  ungroup() %>%
  subset(pair_complete,
         select = -pair_complete) %>%
  droplevels()
```

Our dataset is now reduced from `r length(levels(exclusions.ids$subid_unique))` participants to `r length(levels(exclusions.pairs$subid_unique))`.

## Reported errors

Other than the exclusion criteria reported above, labs reported errors relating to the CDI data gathering. We treat those errors here by hand.

```{r cdi_errors_check}
# Check the different kinds of errors with notes added
errors_check <- exclusions.pairs %>%
  subset(CDI.error) %>%
  select(labid:language_zone) %>%
  mutate_at(vars(Notes), as_factor)
# Are there any errors for which we don't have notes?
(anyNA(errors_check$Notes))
# What kind of errors do we have?
(levels(errors_check$Notes))
```

We have a limited number of error types to process, and no participants that had an error with no attached note. First, we can exclude errors of the type "survey not completed". The "aged out" errors are due to differences in how indivual labs converted age in days to age in months and how we did it in this script, and can be ignored. For the last type of error, "`r last(levels(errors_check$Notes))`"", there does not seem to be an issue with the data itself, and these error can therefore be ignored.

```{r cdi_errors_exclusions}
exclusions.errors <- exclusions.pairs %>%
  subset(!(Notes %in% c("Opened and did not complete the questionnaire",
                        "filled out web-based version but did not complete it",
                        "Participant did not complete survey"))) %>%
  droplevels()
```

Our dataset is now reduced from `r length(levels(exclusions.pairs$subid_unique))` participants to `r length(levels(exclusions.errors$subid_unique))`.

## Final dataset

We now have a full dataset with only participants that matched the inclusion criteria defined in our manuscript. We save this dataset, and move on to computing new variables that are needed for our analysis plan.

```{r save_exclusions}
write_csv(exclusions.errors, "data/02a_exclusions.csv")
```

# New Variables

## `IDS_pref`

We want to create a new variable for the standardized mean preference for IDS `z_IDS_pref`. To do so, we first need to compute the IDS preference for each pair of trials for each infants. We also need to compute the average looking time across both ADS and IDS trials.

```{r ids_preference}
df.final <- exclusions.errors %>%
  select(-trial_num) %>% # Not relevant, we only want the pair number
  pivot_wider(names_from = trial_type, values_from = looking_time) %>%
  mutate(IDS_pref_pair = IDS - ADS,
         mean_LT_pair = (IDS + ADS) / 2)
```

We then need to compute the mean preference for IDS for each infant, and the mean looking time across trials for each infant, to finally get our standardized preference score for IDS.

```{r z_ids_preference}
df.final <- df.final %>%
  group_by(subid_unique) %>%
  mutate(mean_IDS_pref = mean(IDS_pref_pair),
         mean_LT = mean(mean_LT_pair),
         IDS_pref = mean_IDS_pref / mean_LT) %>%
  ungroup() %>%
  select(-c(stimulus_num, IDS, ADS, IDS_pref_pair, mean_LT_pair, mean_IDS_pref, mean_LT)) %>%
  unique()
```

## `CDI.z_age_months`, `z_age_months`

A common way to get better computational models both in terms of estimate precision and convergence is to center and scale numerical variables, particularly ones that have relatively large values and/or large spreads. In our case, age in days are such variables. However, for better interpretation and generalisation of the results, we choose to center those values, but instead of scaling them we simply convert them to ages in months.

```{r z_age_days}
df.final <- df.final %>%
  mutate(z_age_months = as.numeric(scale(age_days, scale = F)/365*12)) %>%
  group_by(CDI.agerange) %>%
  mutate(CDI.z_age_months = scale(CDI.agedays, scale = F)/365*12) %>%
  ungroup()
```

## `z_standardized_CDI`, `z_vocab_nwords`

We discussed above the interest of scaling numerical variables. In our case, our dependant variables are also numerical with high values and wide spreads, so scaling and centring them can sensibly improve model convergence and model fit.

```{r z_CDI_scores}
df.final <- df.final %>%
  mutate(z_standardized_CDI = scale(standardized.score.CDI.num),
         z_vocab_nwords = scale(vocab_nwords))
```

# Conclusion

In the end, our dataset consists of `r length(levels(df.final$subid_unique))` infants and `r nrow(df.final)` CDI scores at 18 or 24 months.

```{r data_summary}
write_csv(df.final, "data/02b_processed.csv")
df.final %>% count(CDI.agerange)
```
