---
title: "MB1 CDI Follow-up Confirmatory Analysis"
author: "The ManyBabies Analysis Team"
date: '`r format(Sys.time(), "%a %b %d %X %Y")`'
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: yes
---

# Introduction

In this script, we go through all the pre-registered proposed analyses. As a reminder, the main research questions where as follows:

1. To what extent does infants' preference for IDS as measured in a laboratory setting predict their vocabulary at 18 and 24 months?
2. Does the relation between IDS preference and vocabulary size change over development?
3. Are there systematic differences in the strength of this relationship across the language communities in our sample?

We first present the main "sample theory based" analyses (also known as frequentist), separately on the North American and UK samples in parallel to answer our first two research questions, then on the total dataset to answer our third research question. We then provide additional Bayesian statistics where a null effect was found, as specified in the pre-registration.

```{r setup, message=FALSE, warning=FALSE}
# Library imports, general settings ==============
library(tidyverse); library(egg)
library(knitr)
library(lme4); library(simr)
library(brms); library(rstan)

theme_set(theme_bw(base_size = 10))
knitr::opts_chunk$set(cache = TRUE)

# Read data ======================================
col_types <- cols(
  labid = col_factor(),
  subid = col_factor(),
  subid_unique = col_factor(),
  CDI.form = col_factor(),
  CDI.nwords = col_integer(),
  CDI.prop = col_number(),
  CDI.agerange = col_factor(),
  CDI.agedays = col_integer(),
  CDI.agemin = col_integer(),
  CDI.agemax = col_integer(),
  vocab_nwords = col_integer(),
  standardized.score.CDI = col_character(),
  standardized.score.CDI.num = col_number(),
  IDS_pref = col_number(),
  language = col_factor(),
  language_zone = col_factor(),
  CDI.error = col_logical(),
  Notes = col_character(),
  trial_order = col_factor(),
  method = col_factor(),
  age_days = col_integer(),
  age_mo = col_number(),
  age_group = col_factor(),
  nae = col_logical(),
  gender = col_factor(),
  second_session = col_logical()
)
data.total <- read_csv("data/02b_processed.csv", col_types = col_types)
```

Before moving on with the analysis, we have to ready the data by (a) checking for colinearity between `z_age_months` and `CDI.z_age_months` and correcting this if necessary, and (b) setting up the contrasts described in our data analysis.

## Colinearity check

First, we run a Kappa test on the possibility of colinearity between `z_age_months` and `CDI.z_age_months`.

```{r colinearity_check}
# Run kappa test
k.age_months <- model.matrix(~ z_age_months + CDI.z_age_months, data = data.total) %>% kappa()
```

With a value of `r k.age_months`, we do not have a colinearity issue and can proceed with the data analysis as planned.

## Contrast Setups

We need `gender` as an effect-coded factor, and `method` as a deviation-coded factor. This is achieved in R by using the `contr.sum()` function with the number of levels for each factor. Notably, when subsetting the NAE and UK samples, only two levels of `method` out of the three in total were left. [NOTE FROM MELANIE: I think you mean just the UK sample? NAE has all three]

```{r contrasts}
# Set contrasts on the total dataset =============
contrasts(data.total$gender) <- contr.sum(2)
contrasts(data.total$method) <- contr.sum(3)
# Create sub-datasets, with contrasts ============
## NAE
data.nae <- data.total %>% subset(language_zone == "NAE") %>% droplevels()
contrasts(data.nae$gender) <- contr.sum(2)
contrasts(data.nae$method) <- contr.sum(3)
## UK
data.uk <- data.total %>% subset(language_zone == "British") %>% droplevels()
contrasts(data.uk$gender) <- contr.sum(2)
contrasts(data.uk$method) <- contr.sum(2)
## Other
data.other <- data.total %>% subset(language_zone == "Other") %>% droplevels()
contrasts(data.other$gender) <- contr.sum(2)
contrasts(data.other$method) <- contr.sum(3)
```

# Descriptive Statistics

We first assess the amount of data we have overall per condition and their shape overall.

```{r desc_total}
data.total %>%
  group_by(language_zone, CDI.agerange, method, gender) %>%
  summarise(N = n(), age = mean(CDI.agedays), sd = sd(CDI.agedays)) %>%
  kable()
```

We then assess the data per lab in terms of sample size and CDI score (vocabulary size, for consistency between language zones).

```{r desc_by_lab}
by_lab <- data.total %>%
  group_by(labid, language_zone, CDI.agerange) %>%
  mutate(tested = n_distinct(subid_unique)) %>%
  select(labid, language_zone, CDI.agerange, tested, vocab_nwords) %>%
  nest(scores = vocab_nwords) %>%
  mutate(model = map(scores, ~ lm(vocab_nwords ~ 1, data = .x)),
         ci = map(model, confint)) %>%
  transmute(tested = tested,
            mean = map_dbl(model, ~ coefficients(.x)[[1]]),
            ci_lower = map_dbl(ci, 1),
            ci_upper = map_dbl(ci, 2)) %>%
  arrange(language_zone) %>%
  rownames_to_column()

# TODO: find a way to group by language zone?
ggplot(by_lab,
       aes(x = labid, colour = language_zone,
           y = mean, ymin = ci_lower, ymax = ci_upper)) + 
  geom_linerange() + 
  geom_point(aes(size = tested)) + 
  facet_grid(cols = vars(CDI.agerange), scales = "free") + coord_flip(ylim = c(0, 500)) +
  xlab("Lab") + ylab("Vocabulary size") +
  scale_colour_brewer(palette = "Dark2", name = "Language zone",
                      breaks = c("British", "NAE", "Other")) +
  scale_size_continuous(name = "N", breaks = function(x) c(min(x), mean(x), max(x))) +
  theme(legend.position = "bottom")
```

# Sample Theory Based Statistics

## Simple Correlation

First, we want to assess quickly if there is a direct correlation between IDS preference and CDI score, computing a Pearson's product-moment correlation. We use standardized CDI scores for the North American sample, and raw scores for the British sample. [NOTE FROM MELANIE: I'm not sure this makes sense to do with the raw UK scores - since we're collapsing across 18 and 24 month data and the data aren't standardized by age.].

```{r simple_correlation}
# Statistics =====================================
## North American Sample
test.pearson.nae <- cor.test(data.nae$IDS_pref,
                             data.nae$z_standardized_CDI,
                             alternative = "two.sided", method = "pearson")
## UK Sample
test.pearson.uk <- cor.test(data.uk$IDS_pref,
                            data.uk$z_vocab_nwords,
                            alternative = "two.sided", method = "pearson")
# Plots ==========================================
## North American Sample
### Get correlation value for annotation
cor_text <- "paste(italic(R)^2, \" =\")"
cor_value <- round(test.pearson.nae$estimate, 3)
### Build plot
plot.pearson.nae <- data.nae %>%
  ggplot(aes(x = IDS_pref,
             y = standardized.score.CDI.num)) +
  xlab("IDS preference") + ylab("Standardized CDI score") +
  geom_point() +
  geom_smooth(method = lm) +
  annotate("text", x = -.9, y = 51, parse = T, size = 4,
           label = paste(cor_text, cor_value, sep = "~"))
## UK Sample
cor_value <- round(test.pearson.uk$estimate, 3)
plot.pearson.uk <- data.uk %>%
  ggplot(aes(x = IDS_pref,
             y = vocab_nwords)) +
  xlab("IDS preference") + ylab("Vocabulary size (in words)") +
  geom_point() +
  geom_smooth(method = lm) +
  annotate("text", x = .8, y = 150, parse = T, size = 4,
           label = paste(cor_text, cor_value, sep = "~"))
# Global plot
plot.pearson <- ggarrange(plot.pearson.nae, plot.pearson.uk, ncol = 2)
ggsave("plots/scatter_pearson.pdf", plot.pearson,
       units = "mm", width = 180, height = 100, dpi = 1000)
(plot.pearson)
```

We see no obvious direct link between IDS prefernce and CDI score here. However, an effect might appear once we take into account various factors that might interact with IDS preference and/or CDI score. We can also first enhance these plots with information about the age group at which infants were tested (18- or 24-month-old), using vocabulary size to better compare the NAE and UK samples.

```{r plot_by_age}
plot.age_group <- data.total %>%
  subset(language_zone != "Other") %>%
  droplevels() %>%
  ggplot(aes(x = IDS_pref,
             y = vocab_nwords,
             colour = CDI.agerange)) +
  facet_wrap(vars(language_zone),
             labeller = as_labeller(c("British" = "UK samples",
                                      "NAE" = "North Amercian samples"))) +
  xlab("Standardized IDS prefence score") + ylab("Vocabulary size (in words)") + theme(legend.position = "top") +
  geom_point() +
  geom_smooth(method = lm) +
  scale_colour_brewer(palette = "Dark2", name = "Age group",
                      breaks = c("18", "24"),
                      labels = c("18mo", "24m"))
ggsave("plots/scatter_age.pdf", plot.age_group,
       units = "mm", width = 180, height = 100, dpi = 1000)
(plot.age_group)
```

## Mixed-Effects Model by Language Zone

Here, we run a mixed-effects model including only theoretically motivated effects, as described in the pre-registration. We start with the full model bellow, simplifying the random effects structure until it converges.

```{r full_lmer}
# Run models =====================================
## NAE
lmer.full.nae <- lmer(standardized.score.CDI.num ~ CDI.z_age_months + gender +
                        z_age_months + IDS_pref +
                        IDS_pref:method + IDS_pref:CDI.z_age_months + IDS_pref:z_age_months +
                        (1 | labid),
                      data = data.nae)
# Sequentially removed random effects:
# IDS_pref:z_age_months
# IDS_pref:CDI.z_age_months
# IDS_pref:method
# IDS_pref
# z_age_months
# gender
# CDI.z_age_months
## UK
lmer.full.uk <- lmer(z_vocab_nwords ~ CDI.z_age_months + gender +
                       z_age_months + IDS_pref +
                       IDS_pref:method + IDS_pref:CDI.z_age_months + IDS_pref:z_age_months +
                       (1 | labid),
                     data = data.uk)
# Sequentially removed random effects:
# IDS_pref:z_age_months
# IDS_pref:CDI.z_age_months
# IDS_pref:method
# IDS_pref
# z_age_months
# gender
# CDI.z_age_months
```

We then compute *p*-vlues from model comparisons via likelihood ratio tests. The sequential term deletion and likelihood ratio tests are encapsulated in a helper function.

```{r anova_lmer}
source("helper/lmer_lrtests.R")
lmer.lr.nae <- lr_tests.lmer(lmer.full.nae)
lmer.lr.uk <- lr_tests.lmer(lmer.full.uk)
# Models with terms removed are all singular, for both NAE and UK samples
```

We now want to check the statistical power of significant effects, and discard any models with significant effects that do not reach 80% power.

```{r pwr_lmer}
lmer.pwr.nae <- lmer.lr.nae %>%
  as_tibble(rownames = "Parameter") %>%
  subset(`Pr(>Chisq)` < .05) %>%
  mutate(pwr = map_dbl(Parameter,
                       ~ powerSim(lmer.full.nae, test = fixed(.x, method = "lr")) %>% {.$x/.$n}))
lmer.pwr.uk <- lmer.lr.uk %>%
  as_tibble(rownames = "Parameter") %>%
  subset(`Pr(>Chisq)` < .05) %>%
  mutate(pwr = map_dbl(Parameter,
                       ~ powerSim(lmer.full.uk, test = fixed(.x, method = "lr")) %>% {.$x/.$n}))
```

## Combined Sample

For this combined analysis, we first need to restrain the age range for the NAE sample (previously ±2 months, now ±1.5 months).

```{r NAE_agerange}
# Create dataset with British and NAE only
data.uk_nae <- data.total %>%
  subset(language_zone %in% c("British", "NAE")) %>%
  mutate(CDI.agemin = ifelse(language_zone == "NAE",
                             CDI.agemin + round(.5*365.25/12),
                             CDI.agemin),
         CDI.agemax = ifelse(language_zone == "NAE",
                             CDI.agemax - round(.5*365.25/12),
                             CDI.agemax)) %>%
  subset(!(CDI.agedays < CDI.agemin | CDI.agedays > CDI.agemax)) %>%
  droplevels()
# Create contrasts for analysis
contrasts(data.uk_nae$gender) <- contr.sum(2)
contrasts(data.uk_nae$method) <- contr.sum(3)
contrasts(data.uk_nae$language_zone) <- contr.sum(2)
```

We can then run the planned combined analysis adding the main effect and interactions of `language_zone`.

```{r uk_nae_lmer}
lmer.full.uk_nae <- lmer(CDI.prop ~ CDI.z_age_months + language_zone + gender +
                           z_age_months + IDS_pref + IDS_pref:language_zone +
                           IDS_pref:method + IDS_pref:CDI.z_age_months + IDS_pref:z_age_months +
                           (1 + CDI.z_age_months | labid),
                         data = data.uk_nae)
# Sequentially removed random effects:
# IDS_pref:z_age_months
# IDS_pref:CDI.z_age_months
# IDS_pref:method
# IDS_pref:language_zone
# IDS_pref
# z_age_months
# gender
# language_zone
```

We then compute $p$-values and power estimates for those $p$-values as above.

```{r uk_nae_statistics}
# Model comparions
lmer.lr.uk_nae <- lr_tests.lmer(lmer.full.uk_nae)
# Models with effects removed are singular or fail to converge

# Power estimates
lmer.pwr.uk_nae <- lmer.lr.uk_nae %>%
  as_tibble(rownames = "Parameter") %>%
  subset(`Pr(>Chisq)` < .05) %>%
  mutate(pwr = map_dbl(Parameter,
                       ~ powerSim(lmer.full.uk_nae,
                                  test = fixed(.x, method = "lr")) %>% {.$x/.$n}))
```

# Bayesian Statistics
