---
title: "MB1 CDI Follow-up Confirmatory Analysis"
author: "The ManyBabies Analysis Team"
date: '`r format(Sys.time(), "%a %b %d %X %Y")`'
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: yes
---

# Introduction

In this script, we go through all the pre-registered proposed analyses. As a reminder, the main research questions where as follows:

1. To what extent does infants' preference for IDS as measured in a laboratory setting predict their vocabulary at 18 and 24 months?
2. Does the relation between IDS preference and vocabulary size change over development?
3. Are there systematic differences in the strength of this relationship across the language communities in our sample?

We first present the main "sample theory based" analyses (also known as frequentist), separately on the North American and UK samples in parallel to answer our first two research questions, then on the total dataset to answer our third research question. We then provide additional Bayesian statistics where a null effect was found, as specified in the pre-registration.

```{r setup, message=FALSE, warning=FALSE}
# Library imports, general settings ==============
library(tidyverse); library(egg)
library(lme4); library(simr)
library(brms); library(rstan)

theme_set(theme_bw())
knitr::opts_chunk$set(cache = TRUE)

# Read data ======================================
col_types <- cols(
  labid = col_factor(),
  subid = col_factor(),
  subid_unique = col_factor(),
  CDI.form = col_factor(),
  CDI.agerange = col_factor(),
  CDI.agedays = col_integer(),
  vocab_nwords = col_integer(),
  standardized.score.CDI = col_character(),
  standardized.score.CDI.num = col_number(),
  IDS_pref = col_number(),
  language = col_factor(),
  language_zone = col_factor(),
  CDI.error = col_logical(),
  Notes = col_character(),
  trial_order = col_factor(),
  method = col_factor(),
  age_days = col_integer(),
  age_mo = col_number(),
  age_group = col_factor(),
  nae = col_logical(),
  gender = col_factor(),
  second_session = col_logical()
)
data.total <- read_csv("data/02b_processed.csv", col_types = col_types)
```

Before moving on with the analysis, we have to ready the data by (a) checking for colinearity between `z_age_months` and `CDI.z_age_months` and correcting this if necessary, and (b) setting up the contrasts described in our data analysis.

## Colinearity check

First, we run a Kappa test on the possibility of colinearity between `z_age_months` and `CDI.z_age_months`.

```{r colinearity_check}
# Run kappa test
c.age_months <- model.matrix(~ z_age_months + CDI.z_age_months, data = data.total) %>% kappa()
```

With a value of `r c.age_months`, we do not have a colinearity issue and can proceed with the data analysis as planned.

## Contrast Setups

We need `gender` as an effect-coded factor, and `method` as a deviation-coded factor. This is achieved in R by using the `contr.sum()` function with the number of levels for each factor. Notably, when subsetting the NAE and UK samples, only two levels of `method` out of the three in total were left.

```{r contrasts}
# Set contrasts on the total dataset =============
contrasts(data.total$gender) <- contr.sum(2)
contrasts(data.total$method) <- contr.sum(3)
# Create sub-datasets, with contrasts ============
## NAE
data.nae <- data.total %>% subset(language_zone == "NAE") %>% droplevels()
contrasts(data.nae$gender) <- contr.sum(2)
contrasts(data.nae$method) <- contr.sum(3)
## UK
data.uk <- data.total %>% subset(language_zone == "British") %>% droplevels()
contrasts(data.uk$gender) <- contr.sum(2)
contrasts(data.uk$method) <- contr.sum(2)
## Other
data.other <- data.total %>% subset(language_zone == "Other") %>% droplevels()
contrasts(data.other$gender) <- contr.sum(2)
contrasts(data.other$method) <- contr.sum(3)
```

# Sample Theory Based Statistics

## Simple Correlation

First, we want to assess quickly if there is a direct correlation between IDS preference and CDI score, computing a Pearson's product-moment correlation. We use standardized CDI scores for the North American sample, and raw scores for the British sample.

```{r simple_correlation}
# Statistics =====================================
## North American Sample
test.pearson.nae <- cor.test(data.nae$IDS_pref,
                             data.nae$standardized.score.CDI.num,
                             alternative = "two.sided", method = "pearson")
## UK Sample
test.pearson.uk <- cor.test(data.uk$IDS_pref,
                            data.uk$vocab_nwords,
                            alternative = "two.sided", method = "pearson")
# Plots ==========================================
## North American Sample
### Get correlation value for annotation
cor_text <- "paste(italic(R)^2, \" =\")"
cor_value <- round(test.pearson.nae$estimate, 3)
### Build plot
plot.pearson.nae <- data.nae %>%
  ggplot(aes(x = IDS_pref,
             y = standardized.score.CDI.num)) +
  geom_point() +
  geom_smooth(method = lm) +
  annotate("text", x = -.9, y = 47, parse = T, size = 4,
           label = paste(cor_text, cor_value, sep = "~"))
## UK Sample
cor_value <- round(test.pearson.uk$estimate, 3)
plot.pearson.uk <- data.uk %>%
  ggplot(aes(x = IDS_pref,
             y = vocab_nwords)) +
  geom_point() +
  geom_smooth(method = lm) +
  annotate("text", x = .8, y = 150, parse = T, size = 4,
           label = paste(cor_text, cor_value, sep = "~"))
ggarrange(plot.pearson.nae, plot.pearson.uk, ncol = 2)
```

We see no obvious direct link between IDS prefernce and CDI score here. However, an effect might appear once we take into account various factors that might interact with IDS preference and/or CDI score.

## Mixed-Effects Model

Here, we run a mixed-effects model including only theoretically motivated effects, as described in the pre-registration. We start with the full model bellow, simplifying the random effects structure until it converges.

```{r full_lmer}
# Run models =====================================
## NAE
lmer.full.nae <- lmer(standardized.score.CDI.num ~ gender + CDI.z_age_months + IDS_pref +
                        IDS_pref:method + IDS_pref:CDI.z_age_months + IDS_pref:z_age_months +
                        (1 + gender + CDI.z_age_months + IDS_pref + IDS_pref:method +
                           IDS_pref:CDI.z_age_months + IDS_pref:z_age_months | labid),
                      data = data.nae)
# Sequentially removed random effects:
# [list here]
## UK
lmer.full.uk <- lmer(vocab_nwords ~ gender + CDI.z_age_months + IDS_pref +
                       IDS_pref:method + IDS_pref:CDI.z_age_months + IDS_pref:z_age_months +
                       (1 + gender + CDI.z_age_months + IDS_pref + IDS_pref:method +
                          IDS_pref:CDI.z_age_months + IDS_pref:z_age_months | labid),
                     data = data.uk)
# Sequentially removed random effects:
# [list here]
```

We then compute *p*-vlues from model comparisons via likelihood ratio tests. The sequential term deletion and likelihood ratio tests are encapsulated in a helper function.

```{r anova_lmer}
source("helper/lmer_lrtests.R")
lmer.lr.nae <- lr_tests.lmer(lmer.full.nae)
lmer.lr.uk <- lr_tests.lmer(lmer.full.uk)
```

## Combined Sample

# Bayesian Statistics
